{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.layers import (Dropout, Input, Dense, Conv2D, \n",
    "                          MaxPooling2D, GlobalAveragePooling2D, \n",
    "                          UpSampling2D, Conv2DTranspose, \n",
    "                          Reshape, Flatten, Activation, \n",
    "                          BatchNormalization, Concatenate)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.initializers import RandomNormal\n",
    "# from keras.optimizers import adam_v2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import sys\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'English Alphabet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []    #len=1900\n",
    "label = []      #len=1900 \n",
    "for i in range(1, 27):\n",
    " for filename in os.listdir(f'English Alphabet/{i}'):\n",
    "        \n",
    "    img = cv2.imread(os.path.join(f'English Alphabet/{i}', filename))     \n",
    "    gray_img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    resized_image = cv2.resize(gray_img, (32,32))\n",
    "   #  img_flatten = resized_image.reshape(-1)\n",
    "    samples.append(resized_image)\n",
    "    label.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Normalize the image\n",
    "normalized_sample=[]\n",
    "for k in samples:\n",
    "   img_normalized = cv2.normalize(k, None, 0, 1.0,\n",
    "   cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "   normalized_sample.append(k)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(samples[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(samples)\n",
    "y = np.array(label).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomize = np.arange(len(x))\n",
    "np.random.shuffle(randomize)\n",
    "x = x[randomize]\n",
    "y = y[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels one hot\n",
    "y = np.zeros((520, 26))         \n",
    "\n",
    "for i in range(len(label)):\n",
    "    y[i, label[i]-1] = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(32,32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = Input(shape=(32,32, 1))\n",
    "img_conc = Concatenate()([img_input, img_input, img_input]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_basemodel = base_model(img_conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = Flatten()(out_basemodel)\n",
    "out2 = Dense(256, activation='relu')(out1)\n",
    "out3 = Dense(128, activation='relu')(out2)\n",
    "out4 = Dense(64, activation='relu')(out3)\n",
    "out5 = Dense(26, activation='softmax')(out4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(img_input, out5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "13/13 [==============================] - 6s 336ms/step - loss: 20.8982 - accuracy: 0.0240\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 4s 297ms/step - loss: 3.3024 - accuracy: 0.0673\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 4s 289ms/step - loss: 3.1653 - accuracy: 0.0865\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 4s 300ms/step - loss: 3.1435 - accuracy: 0.0938\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 4s 334ms/step - loss: 3.0910 - accuracy: 0.0962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21957baee80>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.14182692766189575% \n",
      " Error on training data: 0.8581730723381042\n",
      "Accuracy on test data: 0.08653846383094788% \n",
      " Error on test data: 0.9134615361690521\n"
     ]
    }
   ],
   "source": [
    "pred_train= model.predict(x_train)\n",
    "scores = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
    " \n",
    "pred_test= model.predict(x_test)\n",
    "scores2 = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1])) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
